{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117c5991-97f9-4955-98c4-3df05133b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from Arm_Lib import Arm_Device\n",
    "import roboticstoolbox as rtb\n",
    "from roboticstoolbox import *\n",
    "from spatialmath import *\n",
    "import math\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import cv2\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from datetime import datetime\n",
    "import os\n",
    "import threading\n",
    "from spatialmath import SE3\n",
    "from spatialmath.base import e2h,h2e\n",
    "from machinevisiontoolbox import CentralCamera #针孔相机模型\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib widget\n",
    "Arm  = Arm_Device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c283528-d3c8-4c40-8b3a-a36dd00dca2c",
   "metadata": {},
   "source": [
    "Part1：Robot Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fa75bd-d715-4b98-a87b-5e8b6039c6ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"DH标定\"\"\"\n",
    "#相机DH\n",
    "DFbot1 = DHRobot(\n",
    "    [\n",
    "        RevoluteMDH(d=0.04145,qlim=np.array([-np.pi,np.pi])),\n",
    "        RevoluteMDH(alpha=np.pi/2,qlim=np.array([-np.pi,np.pi])),\n",
    "        RevoluteMDH(a=-0.08285,qlim=np.array([-np.pi,np.pi])),\n",
    "        RevoluteMDH(a=-0.08285,qlim=np.array([-np.pi,np.pi])),\n",
    "        RevoluteMDH(alpha=-np.pi/2,qlim=np.array([0,np.pi])),\n",
    "        RevoluteMDH(a=0.0481,d=0.0657,qlim=np.array([-np.pi,np.pi]))\n",
    "    ],\n",
    "    name = \"DFbot\",\n",
    ")\n",
    "\n",
    "#夹爪DH\n",
    "DFbot2 = DHRobot(\n",
    "    [\n",
    "        RevoluteDH(d=0.04145,alpha=np.pi/2,qlim=np.array([-np.pi/2,np.pi/2])),\n",
    "        RevoluteDH(a=-0.08285,qlim=np.array([-np.pi,0])),\n",
    "        RevoluteDH(a=-0.08285,qlim=np.array([-np.pi/2,np.pi/2])),\n",
    "        RevoluteDH(alpha=-np.pi/2,qlim=np.array([0,np.pi])),\n",
    "        RevoluteDH(d=0.18,qlim=np.array([-np.pi/2,3*np.pi/2]))\n",
    "    ],\n",
    "    name = \"DFbot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86998802-ebf5-4170-8b45-1e16198ecb26",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#夹爪开合角 (degree)\n",
    "claw_open = 150\n",
    "claw_close = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd9e803-adfa-4abc-a8b8-3f3b05d7dc6c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#常见关节空间\n",
    "vertical = [0,-90,0,90,0,claw_open]\n",
    "origin = [0,0,0,0,0,claw_close]\n",
    "cam_calibration=[0,-180,90,180,0,claw_close]\n",
    "photo1 = [0,-120,90,180,0,claw_open]\n",
    "photo2 = [0,-60,60,180,0,claw_open]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89ace80-d938-43db-89e2-c5bc4b2e8db5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"相机内参\n",
    "\"\"\"\n",
    "cam = CentralCamera(f=[934.44192173e-6,939.51291465e-6],rho = 1e-6, imagesize=[640,480], pp=[333.2247427,171.10048061])\n",
    "\n",
    "mtx = cam.K\n",
    "\n",
    "dist = np.array([[-5.35651039e-01,  1.53009433e+00,  1.47216506e-04,\n",
    "        -2.40415479e-03, -3.83108955e+00]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bb7121-9fbd-4559-8966-7ced146f1adc",
   "metadata": {},
   "source": [
    "Part2: Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc7f100-6ca7-4acf-b9ce-4cfeb975bef2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"角度弧度转换:degreeToRadian和RadianToDegree\n",
    "\"\"\"\n",
    "def degreeToRadian(degree_list):\n",
    "    return [math.radians(degree) for degree in degree_list]\n",
    "def radianToDegree(radian_list):\n",
    "    return [math.degrees(radian) for radian in radian_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa48e9e-1f5d-4882-b73b-84d07b12e48d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"获取当前关节角：readJointAngles\n",
    "功能：获取当前（5或6）关节角度，选择角度或者弧度\n",
    "返回：list\n",
    "\"\"\"\n",
    "def readJointAngles(unit=\"degree\",joint=5):\n",
    "    \n",
    "    current_position = []\n",
    "    for i in range(joint):\n",
    "            angle=Arm.Arm_serial_servo_read(i+1)\n",
    "            if angle is None:\n",
    "                raise ValueError(f\"Failed to read current position for joint {i+1}\")\n",
    "            current_position.append(angle)\n",
    "        \n",
    "    #角度处理\n",
    "    current_position[0] = +current_position[0] - 90\n",
    "    current_position[1] = -current_position[1]\n",
    "    current_position[2] = -current_position[2] + 90\n",
    "    current_position[3] = -current_position[3] + 180\n",
    "    current_position[4] = +current_position[4] - 90\n",
    "    if joint==6: current_position[5] = 180-current_position[5]\n",
    "\n",
    "    #转换弧度\n",
    "    if unit==\"radian\":\n",
    "        return degreeToRadian(current_position)\n",
    "        \n",
    "    return current_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c548b1d3-18ba-4e8c-b4ee-717c6d9a83d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Direct_control: 直接对机械臂进行带速度限制的6关节控制\n",
    "输入：形状为（6，）的六关节角度，in degree\n",
    "功能：关节限位检测，运动速度限制，机械臂按照关节空间运动\n",
    "返回：抵达的6关节空间，运动时间（ms）\n",
    "\"\"\"\n",
    "def Direct_control(joint_angles):#joint_angle为一个（6，）的numpy array\n",
    "\n",
    "    # 确保输入是numpy数组\n",
    "    joint_angles = np.asarray(joint_angles)\n",
    "    \n",
    "    # 检查输入形状是否正确\n",
    "    if joint_angles.shape != (6,):\n",
    "        raise ValueError(\"The shape of input angles must be 6!\")\n",
    "    \n",
    "    # 计算新的关节角\n",
    "    j1 = +joint_angles[0] + 90\n",
    "    j2 = -joint_angles[1]\n",
    "    j3 = -joint_angles[2] + 90\n",
    "    j4 = -joint_angles[3] + 180\n",
    "    j5 = +joint_angles[4] + 90\n",
    "    j6 = -joint_angles[5] + 180 #input的角越小，夹爪越收紧！\n",
    "\n",
    "    #关节限位检测\n",
    "    if (j1<0)or(j1>180):\n",
    "        raise ValueError(\"Joint angle 1 exceeds the range!\")\n",
    "    elif (j2<0)or(j2>180):\n",
    "        raise ValueError(\"Joint angle 2 exceeds the range!\")\n",
    "    elif (j3<0)or(j3>180):\n",
    "        raise ValueError(\"Joint angle 3 exceeds the range!\")\n",
    "    elif (j4<0)or(j4>180):\n",
    "        raise ValueError(\"Joint angle 4 exceeds the range!\")\n",
    "    elif(j5<0)or(j5>270):\n",
    "        raise ValueError(\"Joint angle 5 exceeds the range!\")\n",
    "    elif(j6<0)or(j6>180):\n",
    "        raise ValueError(\"Joint angle 6 exceeds the range!\")\n",
    "\n",
    "    #限制运动速度：\n",
    "    target = np.array([j1,j2,j3,j4,j5,j6])\n",
    "    current_position = []\n",
    "    for i in range(6):\n",
    "            angle=Arm.Arm_serial_servo_read(i+1)\n",
    "            if angle is None:\n",
    "                raise ValueError(f\"Failed to read current position for joint {i+1}\")\n",
    "            current_position.append(angle)\n",
    "    angle_difference = np.abs(np.array(current_position)-target)\n",
    "    biased_angle_difference = angle_difference.copy()\n",
    "    biased_angle_difference[1:4] *= 3 #给2，3，4关节时间更长，给1，5，6关节时间可以稍微短\n",
    "    max_angle_movement = np.max(biased_angle_difference)\n",
    "    time = max_angle_movement * 1000 / 60\n",
    "\n",
    "    Arm.Arm_serial_servo_write6(j1,j2,j3,j4,j5,j6, time.astype(int))\n",
    "    return [j1,j2,j3,j4,j5,j6],time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3c250cc-05cb-448e-862b-81b10314ba40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"计算FK和仿真：calculateFK,poseSimu\n",
    "输入：（5或6）关节角度，in degree，相机或夹爪\n",
    "功能：计算和仿真FK\n",
    "返回：Transform matrix或仿真\n",
    "\"\"\"\n",
    "def calculateFK(joint_angles,DH=2):\n",
    "\n",
    "    joint_angles = degreeToRadian(joint_angles)\n",
    "    motor_angles = joint_angles[:5]\n",
    "    \n",
    "    if DH == 1: return DFbot1.fkine(np.hstack([motor_angles,0]))\n",
    "        \n",
    "    else: \n",
    "        return DFbot2.fkine(motor_angles)\n",
    "\n",
    "def poseSimu(joint_angles,DH=2):\n",
    "    joint_angles = degreeToRadian(joint_angles)\n",
    "    motor_angles = joint_angles[:5]\n",
    "    \n",
    "    if DH == 1: DFbot1.plot(np.hstack([motor_angles,0]))\n",
    "    else: DFbot2.plot(motor_angles)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ddef612-a45d-4bed-92c3-c280a1443e82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"计算IK:calculateIK\n",
    "输入：夹爪的位姿矩阵，初始关节空间，ilimit，slimit，joint_limit\n",
    "功能：通过ik-LM优化算法计算距离q0最近的关节空间\n",
    "返回：（degree）五关节的关节空间\n",
    "\"\"\"\n",
    "def calculateIK(T1,q0=[0,0,0,0,0],slimit=1000,ilimit=5000,tol=0.002,joint_limit=True):\n",
    "    T1 = np.array(T1)\n",
    "    if T1.shape[0]!=4 or T1.shape[1]!=4:\n",
    "        raise ValueError(\"The input array has wrong shape!\")\n",
    "    #sol = DFbot2.ikine_LM(T1,q0,slimit=slimit,ilimit=ilimit,tol=tol,joint_limits=joint_limit,mask=[50,10,20,0.1,0.1,0.1])\n",
    "    sol = DFbot2.ikine_LM(T1,q0,slimit=slimit,ilimit=ilimit,tol=tol,joint_limits=joint_limit,mask=[30,30,10,0.1,0.1,0.1])\n",
    "\n",
    "    if sol.reason=='Success':\n",
    "        return radianToDegree(sol.q)\n",
    "    else: raise ValueError(\"Cannot find a solution!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6d4af75-865e-4876-9287-19589a28df33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"普通视频串流与拍照：start_stream,capture_photo,stop_stream\n",
    "功能：start_stream唤起普通视频串流\n",
    "     capture_photo抓拍，可以传入filename更改名称\n",
    "     stop_stream停止并释放串流\n",
    "\"\"\"\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('captured_photos', exist_ok=True)\n",
    "\n",
    "def start_stream():\n",
    "    \"\"\"Start video streaming from webcam\"\"\"\n",
    "    global camera, image_widget, preview_active\n",
    "    \n",
    "    # Initialize camera\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    if not camera.isOpened():\n",
    "        raise Exception(\"Could not open camera\")\n",
    "    \n",
    "    # Create image widget for display\n",
    "    image_widget = widgets.Image(format='jpeg', width=600, height=500)\n",
    "    display(image_widget)\n",
    "    \n",
    "    preview_active = True\n",
    "    \n",
    "    def update_frame():\n",
    "        \"\"\"Update the displayed frame\"\"\"\n",
    "        while preview_active:\n",
    "            ret, frame = camera.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                break\n",
    "            # Convert frame to JPEG and display\n",
    "            _, jpeg = cv2.imencode('.jpg', frame)\n",
    "            image_widget.value = jpeg.tobytes()\n",
    "            time.sleep(0.033)  # ~30 FPS\n",
    "    \n",
    "    # Start the streaming in a thread\n",
    "    import threading\n",
    "    threading.Thread(target=update_frame, daemon=True).start()\n",
    "    \n",
    "    print(\"Streaming started - use stop_stream() to stop\")\n",
    "\n",
    "def capture_photo(filename='photo'):\n",
    "    \"\"\"Capture and save a photo from the webcam\"\"\"\n",
    "    global camera\n",
    "    \n",
    "    # Check if camera is available\n",
    "    if 'camera' not in globals() or not camera.isOpened():\n",
    "        print(\"Camera not available - start streaming first\")\n",
    "        return\n",
    "    \n",
    "    ret, frame = camera.read()\n",
    "    if ret:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{filename}_{timestamp}.jpg\"\n",
    "        filepath = os.path.join('captured_photos', filename)\n",
    "        \n",
    "        cv2.imwrite(filepath, frame)\n",
    "        print(f\"Photo saved as: {filepath}\")\n",
    "        \n",
    "        # Display the captured photo\n",
    "        '''\n",
    "        _, jpeg = cv2.imencode('.jpg', frame)\n",
    "        display(widgets.Image(value=jpeg.tobytes(), width=300))\n",
    "        '''\n",
    "    else:\n",
    "        print(\"Failed to capture photo\")\n",
    "\n",
    "def stop_stream():\n",
    "    \"\"\"Stop video streaming and release camera\"\"\"\n",
    "    global preview_active, camera\n",
    "    \n",
    "    if 'preview_active' in globals():\n",
    "        preview_active = False\n",
    "    \n",
    "    if 'camera' in globals() and camera.isOpened():\n",
    "        camera.release()\n",
    "        print(\"Streaming stopped and camera released\")\n",
    "    else:\n",
    "        print(\"No active streaming to stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cce7119-308d-4c03-ab67-58772b4c6177",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"校正图像畸变 undistort_image\n",
    "参数:\n",
    "    image: 输入图像\n",
    "    mtx: 相机内参矩阵\n",
    "    dist: 畸变系数\n",
    "返回:\n",
    "    校正后的图像\n",
    "\"\"\"\n",
    "def undistort_image(image, mtx, dist):\n",
    "    h, w = image.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    dst = cv2.undistort(image, mtx, dist, None, newcameramtx)\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f940697-4994-43e8-af5a-335c21e61a76",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"detect_color_object:带有物块识别的视频串流\n",
    "输入：color为物块颜色\n",
    "功能：识别各个颜色物块边界，按“c”捕捉四个角及中间点，按esc退出,可以选择开启或关闭防畸变功能（开启会切割画面）\n",
    "返回：\n",
    "print(f\"左上: {points[0]}\")\n",
    "print(f\"右上: {points[1]}\")\n",
    "print(f\"右下: {points[2]}\")\n",
    "print(f\"左下: {points[3]}\")\n",
    "print(f\"中心: {points[4]}\")\n",
    "\"\"\"\n",
    "\n",
    "def detect_color_object(color='red'):\n",
    "    \"\"\"\n",
    "    颜色物体检测函数\n",
    "    参数:\n",
    "        color: 要检测的颜色 ('red', 'blue' 或 'green')\n",
    "    返回:\n",
    "        当按下'c'时返回捕捉到的五个点坐标 (四个角点+中心点)\n",
    "    \"\"\"\n",
    "    # 颜色阈值定义\n",
    "    color_dist = {\n",
    "        'red': [\n",
    "            {'Lower': np.array([0, 100, 100]), 'Upper': np.array([10, 255, 255])},\n",
    "            {'Lower': np.array([160, 100, 100]), 'Upper': np.array([180, 255, 255])}\n",
    "        ],\n",
    "        'blue': {'Lower': np.array([70, 70, 70]), 'Upper': np.array([124, 255, 255])},\n",
    "        'green': {'Lower': np.array([35, 43, 35]), 'Upper': np.array([90, 255, 255])},\n",
    "    }\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"camera\", cv2.WINDOW_AUTOSIZE)\n",
    "    if color==\"red\": cv2.namedWindow(\"mask\", cv2.WINDOW_AUTOSIZE)  # 新增mask窗口用于调试\n",
    "    \n",
    "    captured_points = None\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Cannot read camera!\")\n",
    "            break\n",
    "\n",
    "        #畸变修正处理\n",
    "        #frame = undistort_image(frame,mtx,dist)\n",
    "        \n",
    "        # 预处理\n",
    "        gs_frame = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "        hsv = cv2.cvtColor(gs_frame, cv2.COLOR_BGR2HSV)\n",
    "        erode_hsv = cv2.erode(hsv, None, iterations=2)\n",
    "        \n",
    "        # 颜色阈值处理\n",
    "        if color == 'red':\n",
    "            lower1 = color_dist[color][0]['Lower']\n",
    "            upper1 = color_dist[color][0]['Upper']\n",
    "            lower2 = color_dist[color][1]['Lower']\n",
    "            upper2 = color_dist[color][1]['Upper']\n",
    "            \n",
    "            mask1 = cv2.inRange(erode_hsv, lower1, upper1)\n",
    "            mask2 = cv2.inRange(erode_hsv, lower2, upper2)\n",
    "            inRange_hsv = cv2.bitwise_or(mask1, mask2)\n",
    "            inRange_hsv = cv2.dilate(inRange_hsv, None, iterations=1)\n",
    "        else:\n",
    "            inRange_hsv = cv2.inRange(erode_hsv, \n",
    "                                     color_dist[color]['Lower'], \n",
    "                                     color_dist[color]['Upper'])\n",
    "        \n",
    "        if color==\"red\": cv2.imshow('mask', inRange_hsv)\n",
    "        \n",
    "        # 查找轮廓\n",
    "        cnts = cv2.findContours(inRange_hsv.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        \n",
    "        if cnts:\n",
    "            cnts = [c for c in cnts if cv2.contourArea(c) > 500]\n",
    "            \n",
    "            if cnts:\n",
    "                c = max(cnts, key=cv2.contourArea)\n",
    "                rect = cv2.minAreaRect(c)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                \n",
    "                # 绘制边界框和点\n",
    "                cv2.drawContours(frame, [box], -1, (0, 255, 255), 2)\n",
    "                \n",
    "                # 绘制四个角点坐标\n",
    "                points = []\n",
    "                for i, point in enumerate(box):\n",
    "                    x, y = point\n",
    "                    points.append((x, y))\n",
    "                    cv2.putText(frame, f\"{x},{y}\", (x, y), \n",
    "                               cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.75, (0, 255, 255), 1)\n",
    "                \n",
    "                # 计算中心点\n",
    "                center_x = int((box[3][0] + box[1][0]) / 2)\n",
    "                center_y = int((box[3][1] + box[1][1]) / 2)\n",
    "                center = (center_x, center_y)\n",
    "                points.append(center)\n",
    "                cv2.putText(frame, f\"{center_x},{center_y}\", center,\n",
    "                           cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.75, (0, 255, 255), 1)\n",
    "                \n",
    "                # 检查是否按下'c'键捕获坐标\n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 99:  # 'c'键\n",
    "                    captured_points = points\n",
    "                    break\n",
    "                elif key == 27:  # ESC键\n",
    "                    break\n",
    "        \n",
    "        cv2.imshow('camera', frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:  # ESC键\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return captured_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ef9697-1280-4847-bb46-b32b90e747ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"关节插值和空间位姿插值控制：joint_interpolation,cartesian_interpolation\n",
    "输入：\n",
    "    关节插值：state1为目标6关节角（degree），state0读取当前关节角\n",
    "\"\"\"\n",
    "def joint_interpolation(state1,step=30):\n",
    "    \n",
    "    state0 = readJointAngles(joint=6,unit=\"radian\")\n",
    "    state1 = degreeToRadian(state1)\n",
    "\n",
    "    qt = rtb.tools.trajectory.jtraj(state0,state1,step)\n",
    "\n",
    "    for i in range(step):\n",
    "        state = radianToDegree(qt.q[i])\n",
    "        Direct_control(state)\n",
    "        time.sleep(0.01)\n",
    "    return qt.q\n",
    "\n",
    "def cartesian_interpolation(T1,step=30):\n",
    "    current_joint_angles = readJointAngles()\n",
    "    T0 = calculateFK(current_joint_angles)\n",
    "    if T1.shape[0]!=4 or T1.shape[1]!=4:\n",
    "        raise ValueError(\"The input array has wrong shape!\")\n",
    "    print(\"Initial position:\",current_joint_angles)\n",
    "    qt = rtb.tools.trajectory.ctraj(T0,T1,step) #获得离散的T矩阵\n",
    "    pose_list = []\n",
    "    for i in range(len(qt)):\n",
    "       # current_joint_angles = readJointAngles()\n",
    "        pose = calculateIK(qt[i],q0=current_joint_angles,tol=0.005)\n",
    "        pose_list.append(pose)\n",
    "        Direct_control(np.hstack((pose,claw_close)))\n",
    "        #time.sleep(0.01)\n",
    "    return pose_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc9ea64f-9398-4961-814d-e27bb0d2355c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"欧拉角-旋转矩阵相互转换：matrix_to_euler, euler_to_matrix\n",
    "输入：\n",
    "    matrix_to_euler:其次变换矩阵T/旋转矩阵R\n",
    "    euler_to_matrix:欧拉角（in degree）—— roll（绕x），pitch（绕y），yaw（绕z）\n",
    "    旋转顺序按照roll-pitch-yaw，按照固定世界基底坐标系旋转！\n",
    "输出：欧拉角，3x3旋转矩阵\n",
    "\"\"\"\n",
    "def matrix_to_euler(T):\n",
    "    T = np.asarray(T)\n",
    "    R = T[0:3,0:3]\n",
    "    # 计算Pitch (θ)\n",
    "    theta = math.atan2(-R[2, 0], math.sqrt(R[0, 0]**2 + R[1, 0]**2))\n",
    "    \n",
    "    # 处理万向节锁的情况\n",
    "    if abs(theta - math.pi/2) < 1e-6:\n",
    "        phi = 0\n",
    "        psi = math.atan2(R[0, 1], R[1, 1])\n",
    "    elif abs(theta + math.pi/2) < 1e-6:\n",
    "        phi = 0\n",
    "        psi = -math.atan2(R[0, 1], R[1, 1])\n",
    "    else:\n",
    "        # 计算Roll (φ)和Yaw (ψ)\n",
    "        phi = math.atan2(R[2, 1], R[2, 2])\n",
    "        psi = math.atan2(R[1, 0], R[0, 0])\n",
    "    \n",
    "    return radianToDegree([phi, theta, psi])\n",
    "\n",
    "def euler_to_matrix(roll, pitch, yaw):\n",
    "    roll = math.radians(roll)\n",
    "    pitch = math.radians(pitch)\n",
    "    yaw = math.radians(yaw)\n",
    "    # 计算各旋转矩阵\n",
    "    Rx = np.array([\n",
    "        [1, 0, 0],\n",
    "        [0, math.cos(roll), -math.sin(roll)],\n",
    "        [0, math.sin(roll), math.cos(roll)]\n",
    "    ])\n",
    "    \n",
    "    Ry = np.array([\n",
    "        [math.cos(pitch), 0, math.sin(pitch)],\n",
    "        [0, 1, 0],\n",
    "        [-math.sin(pitch), 0, math.cos(pitch)]\n",
    "    ])\n",
    "    \n",
    "    Rz = np.array([\n",
    "        [math.cos(yaw), -math.sin(yaw), 0],\n",
    "        [math.sin(yaw), math.cos(yaw), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # 组合旋转矩阵 R = Rz * Ry * Rx\n",
    "    R = np.dot(Rz, np.dot(Ry, Rx))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4358f-6a78-455b-8c03-10d63868c24c",
   "metadata": {},
   "source": [
    "Part3: Task--Watch-Pick-Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cf34c-c193-410a-afad-da0e215230a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Direct_control(photo2) #到达相机识别位姿\n",
    "pose = calculateFK(photo2,DH=1)\n",
    "depth = 0.115\n",
    "K = mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c66f2-f3ce-48ba-ad2b-f79b3f81a6a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"将3D世界坐标点投影到2D图像平面:project_3d_to_2d\n",
    "参数:\n",
    "    point_3d - 世界坐标系中的3D点(齐次坐标[x,y,z,1])\n",
    "    K - 相机内参矩阵(3x3)\n",
    "    pose - 相机位姿矩阵(4x4, 相机到世界的变换矩阵)\n",
    "返回:\n",
    "    point_2d - 图像平面上的2D坐标(像素坐标[u,v])\n",
    "    depth - 深度值(相机坐标系下的z坐标)\n",
    "\"\"\"\n",
    "def project_3d_to_2d(point_3d, K, pose):\n",
    "    # 确保所有矩阵都是numpy数组\n",
    "    point_3d = np.hstack((np.array(point_3d),1))\n",
    "    K = np.array(K)\n",
    "    pose = np.array(pose)\n",
    "    \n",
    "    # 将3D点从世界坐标系转换到相机坐标系\n",
    "    extrinsic = np.linalg.inv(pose)\n",
    "    point_camera = extrinsic @ point_3d\n",
    "    \n",
    "    # 获取深度(相机坐标系下的z坐标)\n",
    "    depth = point_camera[2]\n",
    "    \n",
    "    # 投影到图像平面\n",
    "    point_2d_homogeneous = K @ point_camera[:3]\n",
    "    point_2d = point_2d_homogeneous[:2] / point_2d_homogeneous[2]\n",
    "    \n",
    "    return point_2d, depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc6e09-2313-48a7-9817-2b82b8d116e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"将2D图像点反投影到3D空间:backproject_2d_to_3d\n",
    "\n",
    "参数:\n",
    "    point_2d - 图像平面上的2D坐标(像素坐标[u,v])\n",
    "    depth - 深度值(相机坐标系下的z坐标)\n",
    "    K - 相机内参矩阵(3x3)\n",
    "    pose - 相机位姿矩阵(4x4, 相机到世界的变换矩阵)\n",
    "\n",
    "返回:\n",
    "    point_3d - 世界坐标系中的3D点(齐次坐标[x,y,z,1])\n",
    "\"\"\"\n",
    "def backproject_2d_to_3d(point_2d, depth, K, pose):\n",
    "\n",
    "    # 确保所有矩阵都是numpy数组\n",
    "    K = np.array(K)\n",
    "    pose = np.array(pose)\n",
    "    \n",
    "    # 将2D点转换为相机坐标系下的3D点\n",
    "    point_2d_homogeneous = np.append(point_2d, 1)\n",
    "    point_camera = depth * (np.linalg.inv(K) @ point_2d_homogeneous)\n",
    "    \n",
    "    # 转换为齐次坐标\n",
    "    point_camera_homogeneous = np.append(point_camera, 1)\n",
    "    \n",
    "    # 转换到世界坐标系\n",
    "    point_3d = pose @ point_camera_homogeneous\n",
    "    \n",
    "    return point_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62d9e1-67d0-4197-9ea6-c579c341702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"简化版抓取\n",
    "条件：在可视范围内可以调整x，y，但是不能旋转方块\n",
    "实现：通过识别方块中心点坐标，已知深度实现抓取\n",
    "\"\"\"\n",
    "\n",
    "#step1:获取中心点坐标\n",
    "xaxis,yaxis = detect_color_object()[4] \n",
    "#step2:转换为空间3d坐标\n",
    "new_point_3d = backproject_2d_to_3d([xaxis,yaxis],depth,K,pose) \n",
    "print(\"中心点：\",new_point_3d[:3])\n",
    "\n",
    "#step3:使用此位姿的旋转矩阵构造抓取的位姿\n",
    "#pose2 = np.array(pose) #竖直抓取（成功率较低）\n",
    "pose2 = np.array(calculateFK([0,-45,45,135,0])) #斜45度抓取(近处可能超出工作空间）\n",
    "#pose2 = np.array(calculateFK([0,-45,45,150,0])) #斜60度抓取\n",
    "pose2[:,-1] = new_point_3d.flatten()\n",
    "\n",
    "#step4:计算抓取位姿的IK\n",
    "sol = calculateIK(pose2,tol=0.01)\n",
    "print(\"真实抓取 joint space:\",sol)\n",
    "print(\"真实抓取FK：\\n\",calculateFK(sol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246cb748-2980-42c8-9ff1-0532610b8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行抓取(可人工对上面信息进行检查后运行）\n",
    "Direct_control(np.hstack((sol,claw_open)))\n",
    "time.sleep(2.5)\n",
    "Direct_control(np.hstack((sol,claw_close)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb89d6c-b395-4dab-b205-101704cbf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"完整版抓取\n",
    "条件：在可视范围内可以调整x，y并旋转方块\n",
    "实现：通过识别方块中心点坐标，已知深度实现抓取\n",
    "\"\"\"\n",
    "\n",
    "#step1:获取点坐标\n",
    "points = np.array(detect_color_object())\n",
    "xaxis,yaxis = points[4] \n",
    "#step2:转换为空间3d坐标\n",
    "new_point_3d = backproject_2d_to_3d([xaxis,yaxis],depth,K,pose) \n",
    "print(\"中心点：\",new_point_3d[:3])\n",
    "\n",
    "#step3:使用此位姿的旋转矩阵构造抓取的位姿\n",
    "pose2 = np.array(pose) #竖直抓取（成功率较低）\n",
    "#pose2 = np.array(calculateFK([0,-45,45,135,0])) #斜45度抓取(近处可能超出工作空间）\n",
    "#pose2 = np.array(calculateFK([0,-45,45,150,0])) #斜60度抓取\n",
    "pose2[:,-1] = new_point_3d.flatten()\n",
    "\n",
    "#step4:计算抓取位姿的IK\n",
    "sol = calculateIK(pose2,tol=0.005)\n",
    "print(\"真实抓取 joint space:\",sol)\n",
    "print(\"真实抓取FK：\\n\",calculateFK(sol))\n",
    "\n",
    "#step5:计算物块旋转角度\n",
    "theta1 = math.atan2(points[0,1]-points[1,1],points[0,0]-points[1,0])\n",
    "theta2 = math.atan2(points[3,1]-points[2,1],points[3,0]-points[2,0])\n",
    "theta = math.degrees((theta1+theta2)/2)\n",
    "if theta > 90:\n",
    "    theta = theta - 180\n",
    "    if theta < -45:\n",
    "        theta = theta + 90\n",
    "print(theta1,theta2,\"物块旋转角度：\",theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3478190-7781-464c-8f1d-19b9345a51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行抓取(可人工对上面信息进行检查后运行）\n",
    "Direct_control(np.hstack((sol[0:4],theta,claw_open))) #末端6电机角度在这里修改\n",
    "time.sleep(2.5)\n",
    "#Direct_control(np.hstack((sol[0:4],35,claw_close)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27185891-a2b0-4bd3-92a8-d6a1dc46cfa2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#立方体投影仿真\n",
    "from spatialmath import SE3\n",
    "from machinevisiontoolbox import mkcube\n",
    "X,Y,Z = mkcube(s=0.03,centre=(-0.15,0,-0.06),edge=True)\n",
    "cam.plot_wireframe(X,Y,Z,pose=calculateFK(photo2,DH=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85e2e0-4121-4fe6-83e0-75a0ff91ea5d",
   "metadata": {},
   "source": [
    "Part: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af74b9c-837e-4e2f-8dfa-25f0e6c3ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_interpolation(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62860b-2a6f-48d5-a679-41f4642fd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cartesian_interpolation(calculateFK(vertical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "716fe224-4f32-4a2a-ace8-1652159b4d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([90, 90, 90, 90, 90, 30], 4500.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Direct_control(vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d40230-aa06-435c-96d0-28b7764d29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "readJointAngles(joint=6,unit=\"degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437f4f2-4cf3-43da-8852-6d261cef642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = calculateFK([-30,-45,35,140,60])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260cc73d-1da2-405d-b1ea-cd64b453447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateIK(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d92d5-6bbd-404f-8109-e833ed9093dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "poseSimu([-30,-45,35,140,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72f9c2-546a-4bc1-9899-77f370535aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = calculateFK([0,0,0,-30,0],DH=2)\n",
    "print(b)\n",
    "b = np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951ac5d-5054-412b-997f-c81819c94bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poseSimu(origin,DH=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f0393-7b47-4fe3-b330-afd6386a8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateIK(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7e54f-8de3-4cf6-9417-75827ca8c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495cdcd-d547-45f7-a428-123067eeaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_photo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266e63b-2df0-456c-9215-82f3e96dd9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee0fe9-a3e4-4277-a0ce-01019d1a6bc0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(P)\n",
    "print(project_3d_to_2d(P,K,pose))\n",
    "backproject_2d_to_3d([138.73080609, 171.10048061],0.10750020470354073,K,pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cd480-86e0-4b06-930d-c0d30e8ca810",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = 485\n",
    "yaxis = 316\n",
    "depth = 0.12\n",
    "new_point_3d = backproject_2d_to_3d([xaxis,yaxis],depth,K,pose)\n",
    "print(new_point_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa6441-6355-4e98-a18b-8cf6e79e8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose2 = np.array(calculateFK([0,-45,45,150,0]))\n",
    "pose2[:,-1] = new_point_3d.flatten()\n",
    "pose2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387991b-1890-4c94-939b-affc14178370",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = calculateIK(pose2,tol=0.005)\n",
    "print(sol)\n",
    "calculateFK(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2616a9-ee29-411e-b4e5-966d3f2424d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Direct_control([-5.311222614224444, -65.2227897980361, 82.87588050309691, 136.88339804839927, -4.988827395493744,claw_close])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cccdc6-28ae-4c0a-afb7-19978265db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateFK([-0.7809924107131491,\n",
    " -57.64522352625729,\n",
    " 59.39593307238916,\n",
    " 177.9601331801728,\n",
    " -0.7791658064512503],DH=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae887b-a140-4f45-9e65-3e30791776c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poseSimu([0,-45,45,150,0])\n",
    "x = calculateFK([0,-45,45,150,0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b7626-9705-4816-aad3-442971598072",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_to_euler(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7f73e-5d15-415c-902b-2ad8aa8e0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "euler_to_matrix(0,-150,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c922606-1500-4bd0-9f84-780f91545e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(96, 136), (203, 34), (304, 139), (197, 241), (200, 137)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_color_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b2ea34-f06d-4a00-b519-be054b6cee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1:获取中心点坐标\n",
    "xaxis,yaxis = detect_color_object()[4] \n",
    "#step2:转换为空间3d坐标\n",
    "new_point_3d = backproject_2d_to_3d([xaxis,yaxis],depth,K,pose) \n",
    "\n",
    "roll,pitch,yaw = 0,-180,34\n",
    "R = euler_to_matrix(roll,pitch,yaw)\n",
    "#step3:使用此位姿的旋转矩阵构造抓取的位姿\n",
    "pose2 = np.array(pose) #竖直抓取（成功率较低）\n",
    "#pose2 = np.array(calculateFK([0,-45,45,135,0])) #斜45度抓取(近处可能超出工作空间）\n",
    "#pose2 = np.array(calculateFK([0,-45,45,150,0])) #斜60度抓取\n",
    "pose2[:3,:3] = R\n",
    "pose2[:,-1] = new_point_3d.flatten()\n",
    "print(pose)\n",
    "print(pose2)\n",
    "\n",
    "#step4:计算抓取位姿的IK\n",
    "sol = calculateIK(pose2,tol=0.015)\n",
    "print(\"真实抓取 joint space:\",sol)\n",
    "print(\"真实抓取FK：\\n\",calculateFK(sol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96904853-3837-4dbe-bd4c-7ae458091835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
